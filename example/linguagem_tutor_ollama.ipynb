{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3f483a",
   "metadata": {},
   "source": [
    "# Tutor de qualquer língua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb763da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingua1 = \"português\"\n",
    "lingua2 = \"inglês\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e9a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Você irá dar assistência na tradução de {lingua1} para {lingua2}. Você é o melhor tradutor de línguas do mundo.\n",
    "Você receberá um texto na língua: {lingua1} e deverá traduzir para a língua {lingua2}, sem mais ou menos. Apenas faça\n",
    "a melhor tradução possível.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Traduza o texto abaixo:\n",
    "-----------\n",
    "{sentence}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f983468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "def get_response_tutor(lingua1, lingua2, sentence):\n",
    "\n",
    "  response: ChatResponse = chat(model='gemma3:1b', messages=[\n",
    "    {\n",
    "      'role': 'system',\n",
    "      'content': system_prompt.format(lingua1=lingua1, lingua2=lingua2),\n",
    "    },\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': user_prompt.format(lingua1=lingua1, lingua2=lingua2, sentence=sentence),\n",
    "    },\n",
    "  ])\n",
    "  \n",
    "  return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2a7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tutor = get_response_tutor(\n",
    "    lingua1=\"português\",\n",
    "    lingua2=\"inglês\",\n",
    "    sentence=\"Eai, tudo bem meu querido?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c332c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, how’s it going, my dear?\n"
     ]
    }
   ],
   "source": [
    "print(response_tutor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0e7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tutor = get_response_tutor(\n",
    "    lingua1=\"português\",\n",
    "    lingua2=\"Italiano\",\n",
    "    sentence=\"Onde está a minha esposa?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93099f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dove è la mia moglie?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response_tutor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
